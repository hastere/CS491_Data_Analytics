{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "import numpy as np\n",
    "from keras.layers import Input,Flatten,Dense\n",
    "from keras.models import Model\n",
    "from keras.utils import np_utils\n",
    "from sklearn.utils import shuffle\n",
    "from keras.optimizers import Adam\n",
    "from numpy.random import seed\n",
    "seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the training images\n",
    "    Training images are stored in ~/Task2/Train Folder\n",
    "     Guardrail_Barriers = class 0\n",
    "     RumbleStrips = class 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "classLabels = dict()\n",
    "\n",
    "classLabels[0] = \"Guardrail_Barriers\"\n",
    "classLabels[1] = \"RumbleStrips\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "X_train = []\n",
    "Y_train = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Read training images of class type 'uardrail_Barriers'\n",
    "#Path_of_the_image_folder = \"Provide_path_to_the_Trainfolder_Guardrail_Barriers_here\"\n",
    "#TODO Ends\n",
    "Path_of_the_image_folder = \"Train/Guardrail_Barriers\"\n",
    "for file in os.listdir(Path_of_the_image_folder):\n",
    "    img = image.load_img(Path_of_the_image_folder+'/'+file, target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    #x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    X_train.append(x)\n",
    "    Y_train.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Read images of class type 'RumbleStrips'\n",
    "#Path_of_the_image_folder = \"Provide_path_to_the_Trainfolder_RumbleStrips_here\"\n",
    "#TODO Ends\n",
    "Path_of_the_image_folder = \"Train/RumbleStrips\"\n",
    "for file in os.listdir(Path_of_the_image_folder):\n",
    "    img = image.load_img(Path_of_the_image_folder+'/'+file, target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    #x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    X_train.append(x)\n",
    "    Y_train.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transforming from list to array\n",
    "X_train =np.asarray(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 224, 224, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the shape of the training array should be 100,224,224,3\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "Y_train = np_utils.to_categorical(Y_train, num_classes)\n",
    "X_train, Y_train = shuffle(X_train, Y_train, random_state=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_input = Input(shape=(224, 224, 3))\n",
    "model = ResNet50(input_tensor=image_input, include_top=True,weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, 2)            4098        avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 23,591,810\n",
      "Trainable params: 23,538,690\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "last_layer = model.get_layer('avg_pool').output\n",
    "out = Dense(num_classes, activation='softmax', name='output_layer')(last_layer)\n",
    "custom_resnet_model = Model(inputs=image_input,outputs= out)\n",
    "custom_resnet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in custom_resnet_model.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "\n",
    "custom_resnet_model.layers[-1].trainable\n",
    "\n",
    "custom_resnet_model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.0001),metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model with new training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 70 samples, validate on 30 samples\n",
      "Epoch 1/150\n",
      "70/70 [==============================] - 20s 282ms/step - loss: 0.9297 - acc: 0.5000 - val_loss: 2.0867 - val_acc: 0.4333\n",
      "Epoch 2/150\n",
      "70/70 [==============================] - 13s 188ms/step - loss: 0.8294 - acc: 0.5000 - val_loss: 1.8800 - val_acc: 0.4333\n",
      "Epoch 3/150\n",
      "70/70 [==============================] - 13s 189ms/step - loss: 0.7834 - acc: 0.5429 - val_loss: 1.7760 - val_acc: 0.4333\n",
      "Epoch 4/150\n",
      "70/70 [==============================] - 14s 199ms/step - loss: 0.7653 - acc: 0.5286 - val_loss: 1.7709 - val_acc: 0.4333\n",
      "Epoch 5/150\n",
      "70/70 [==============================] - 14s 195ms/step - loss: 0.7393 - acc: 0.6000 - val_loss: 1.7885 - val_acc: 0.4333\n",
      "Epoch 6/150\n",
      "70/70 [==============================] - 13s 193ms/step - loss: 0.7138 - acc: 0.5857 - val_loss: 1.7729 - val_acc: 0.4333\n",
      "Epoch 7/150\n",
      "70/70 [==============================] - 14s 193ms/step - loss: 0.6836 - acc: 0.6000 - val_loss: 1.7862 - val_acc: 0.4333\n",
      "Epoch 8/150\n",
      "70/70 [==============================] - 15s 208ms/step - loss: 0.6653 - acc: 0.5714 - val_loss: 1.7810 - val_acc: 0.4333\n",
      "Epoch 9/150\n",
      "70/70 [==============================] - 13s 191ms/step - loss: 0.6369 - acc: 0.6571 - val_loss: 1.7988 - val_acc: 0.4333\n",
      "Epoch 10/150\n",
      "70/70 [==============================] - 13s 189ms/step - loss: 0.6308 - acc: 0.6429 - val_loss: 1.8272 - val_acc: 0.4333\n",
      "Epoch 11/150\n",
      "70/70 [==============================] - 13s 191ms/step - loss: 0.6126 - acc: 0.6571 - val_loss: 1.8353 - val_acc: 0.4333\n",
      "Epoch 12/150\n",
      "70/70 [==============================] - 14s 206ms/step - loss: 0.6035 - acc: 0.6857 - val_loss: 1.8515 - val_acc: 0.4333\n",
      "Epoch 13/150\n",
      "70/70 [==============================] - 14s 201ms/step - loss: 0.5983 - acc: 0.7429 - val_loss: 1.8438 - val_acc: 0.4333\n",
      "Epoch 14/150\n",
      "70/70 [==============================] - 14s 198ms/step - loss: 0.5558 - acc: 0.7571 - val_loss: 1.8044 - val_acc: 0.4333\n",
      "Epoch 15/150\n",
      "70/70 [==============================] - 14s 202ms/step - loss: 0.5468 - acc: 0.7571 - val_loss: 1.7293 - val_acc: 0.4333\n",
      "Epoch 16/150\n",
      "70/70 [==============================] - 14s 197ms/step - loss: 0.5298 - acc: 0.7143 - val_loss: 1.6862 - val_acc: 0.4333\n",
      "Epoch 17/150\n",
      "70/70 [==============================] - 14s 205ms/step - loss: 0.5143 - acc: 0.7286 - val_loss: 1.6256 - val_acc: 0.4333\n",
      "Epoch 18/150\n",
      "70/70 [==============================] - 14s 200ms/step - loss: 0.4887 - acc: 0.8000 - val_loss: 1.6388 - val_acc: 0.4333\n",
      "Epoch 19/150\n",
      "70/70 [==============================] - 13s 191ms/step - loss: 0.4643 - acc: 0.8000 - val_loss: 1.6570 - val_acc: 0.4333\n",
      "Epoch 20/150\n",
      "70/70 [==============================] - 13s 189ms/step - loss: 0.4701 - acc: 0.8429 - val_loss: 1.6711 - val_acc: 0.4333\n",
      "Epoch 21/150\n",
      "70/70 [==============================] - 13s 188ms/step - loss: 0.4471 - acc: 0.8429 - val_loss: 1.6511 - val_acc: 0.4333\n",
      "Epoch 22/150\n",
      "70/70 [==============================] - 14s 207ms/step - loss: 0.4564 - acc: 0.8714 - val_loss: 1.6280 - val_acc: 0.4333\n",
      "Epoch 23/150\n",
      "70/70 [==============================] - 15s 216ms/step - loss: 0.4253 - acc: 0.8286 - val_loss: 1.6029 - val_acc: 0.4333\n",
      "Epoch 24/150\n",
      "70/70 [==============================] - 15s 221ms/step - loss: 0.4181 - acc: 0.8714 - val_loss: 1.5899 - val_acc: 0.4333\n",
      "Epoch 25/150\n",
      "70/70 [==============================] - 14s 207ms/step - loss: 0.4151 - acc: 0.8714 - val_loss: 1.5549 - val_acc: 0.4333\n",
      "Epoch 26/150\n",
      "70/70 [==============================] - 14s 196ms/step - loss: 0.3966 - acc: 0.8857 - val_loss: 1.5342 - val_acc: 0.4333\n",
      "Epoch 27/150\n",
      "70/70 [==============================] - 16s 223ms/step - loss: 0.4212 - acc: 0.8571 - val_loss: 1.5496 - val_acc: 0.4333\n",
      "Epoch 28/150\n",
      "70/70 [==============================] - 15s 208ms/step - loss: 0.3941 - acc: 0.8714 - val_loss: 1.5777 - val_acc: 0.4333\n",
      "Epoch 29/150\n",
      "70/70 [==============================] - 15s 208ms/step - loss: 0.3961 - acc: 0.8714 - val_loss: 1.6458 - val_acc: 0.4333\n",
      "Epoch 30/150\n",
      "70/70 [==============================] - 13s 189ms/step - loss: 0.3715 - acc: 0.8286 - val_loss: 1.6420 - val_acc: 0.4333\n",
      "Epoch 31/150\n",
      "70/70 [==============================] - 13s 190ms/step - loss: 0.3668 - acc: 0.9143 - val_loss: 1.6110 - val_acc: 0.4333\n",
      "Epoch 32/150\n",
      "70/70 [==============================] - 13s 189ms/step - loss: 0.3619 - acc: 0.9000 - val_loss: 1.5672 - val_acc: 0.4333\n",
      "Epoch 33/150\n",
      "70/70 [==============================] - 14s 197ms/step - loss: 0.3356 - acc: 0.9286 - val_loss: 1.5438 - val_acc: 0.4333\n",
      "Epoch 34/150\n",
      "70/70 [==============================] - 13s 188ms/step - loss: 0.3301 - acc: 0.9429 - val_loss: 1.5232 - val_acc: 0.4333\n",
      "Epoch 35/150\n",
      "70/70 [==============================] - 16s 224ms/step - loss: 0.3399 - acc: 0.9286 - val_loss: 1.5227 - val_acc: 0.4333\n",
      "Epoch 36/150\n",
      "70/70 [==============================] - 13s 187ms/step - loss: 0.3362 - acc: 0.9429 - val_loss: 1.4970 - val_acc: 0.4333\n",
      "Epoch 37/150\n",
      "70/70 [==============================] - 14s 200ms/step - loss: 0.3307 - acc: 0.9143 - val_loss: 1.4834 - val_acc: 0.4333\n",
      "Epoch 38/150\n",
      "70/70 [==============================] - 14s 198ms/step - loss: 0.3058 - acc: 0.9286 - val_loss: 1.4976 - val_acc: 0.4333\n",
      "Epoch 39/150\n",
      "70/70 [==============================] - 14s 203ms/step - loss: 0.3150 - acc: 0.9286 - val_loss: 1.5030 - val_acc: 0.4333\n",
      "Epoch 40/150\n",
      "70/70 [==============================] - 14s 196ms/step - loss: 0.3108 - acc: 0.9000 - val_loss: 1.5232 - val_acc: 0.4333\n",
      "Epoch 41/150\n",
      "70/70 [==============================] - 14s 194ms/step - loss: 0.2761 - acc: 0.9286 - val_loss: 1.5339 - val_acc: 0.4333\n",
      "Epoch 42/150\n",
      "70/70 [==============================] - 14s 203ms/step - loss: 0.3094 - acc: 0.9000 - val_loss: 1.5123 - val_acc: 0.4333\n",
      "Epoch 43/150\n",
      "70/70 [==============================] - 14s 196ms/step - loss: 0.2911 - acc: 0.9571 - val_loss: 1.4645 - val_acc: 0.4333\n",
      "Epoch 44/150\n",
      "70/70 [==============================] - 14s 202ms/step - loss: 0.2925 - acc: 0.9429 - val_loss: 1.4421 - val_acc: 0.4333\n",
      "Epoch 45/150\n",
      "70/70 [==============================] - 14s 196ms/step - loss: 0.2887 - acc: 0.9286 - val_loss: 1.4164 - val_acc: 0.4333\n",
      "Epoch 46/150\n",
      "70/70 [==============================] - 13s 192ms/step - loss: 0.2920 - acc: 0.9571 - val_loss: 1.4112 - val_acc: 0.4333\n",
      "Epoch 47/150\n",
      "70/70 [==============================] - 14s 202ms/step - loss: 0.2740 - acc: 0.9571 - val_loss: 1.3930 - val_acc: 0.4333\n",
      "Epoch 48/150\n",
      "70/70 [==============================] - 14s 198ms/step - loss: 0.2579 - acc: 0.9571 - val_loss: 1.3847 - val_acc: 0.4333\n",
      "Epoch 49/150\n",
      "70/70 [==============================] - 14s 200ms/step - loss: 0.2596 - acc: 0.9857 - val_loss: 1.3801 - val_acc: 0.4333\n",
      "Epoch 50/150\n",
      "70/70 [==============================] - 14s 205ms/step - loss: 0.2721 - acc: 0.9571 - val_loss: 1.3850 - val_acc: 0.4333\n",
      "Epoch 51/150\n",
      "70/70 [==============================] - 14s 203ms/step - loss: 0.2750 - acc: 0.9429 - val_loss: 1.3932 - val_acc: 0.4333\n",
      "Epoch 52/150\n",
      "70/70 [==============================] - 14s 201ms/step - loss: 0.2618 - acc: 0.9429 - val_loss: 1.4180 - val_acc: 0.4333\n",
      "Epoch 53/150\n",
      "70/70 [==============================] - 14s 197ms/step - loss: 0.2426 - acc: 0.9429 - val_loss: 1.4540 - val_acc: 0.4333\n",
      "Epoch 54/150\n",
      "70/70 [==============================] - 13s 191ms/step - loss: 0.2317 - acc: 1.0000 - val_loss: 1.4437 - val_acc: 0.4333\n",
      "Epoch 55/150\n",
      "70/70 [==============================] - 14s 195ms/step - loss: 0.2497 - acc: 0.9714 - val_loss: 1.4158 - val_acc: 0.4333\n",
      "Epoch 56/150\n",
      "70/70 [==============================] - 16s 224ms/step - loss: 0.2578 - acc: 0.9429 - val_loss: 1.4134 - val_acc: 0.4333\n",
      "Epoch 57/150\n",
      "70/70 [==============================] - 19s 266ms/step - loss: 0.2330 - acc: 0.9714 - val_loss: 1.4202 - val_acc: 0.4333\n",
      "Epoch 58/150\n",
      "70/70 [==============================] - 15s 210ms/step - loss: 0.2364 - acc: 0.9571 - val_loss: 1.3860 - val_acc: 0.4333\n",
      "Epoch 59/150\n",
      "70/70 [==============================] - 14s 197ms/step - loss: 0.2195 - acc: 0.9857 - val_loss: 1.3783 - val_acc: 0.4333\n",
      "Epoch 60/150\n",
      "70/70 [==============================] - 14s 201ms/step - loss: 0.2151 - acc: 0.9429 - val_loss: 1.3593 - val_acc: 0.4333\n",
      "Epoch 61/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 14s 197ms/step - loss: 0.2292 - acc: 0.9857 - val_loss: 1.3332 - val_acc: 0.4333\n",
      "Epoch 62/150\n",
      "70/70 [==============================] - 14s 202ms/step - loss: 0.2415 - acc: 0.9714 - val_loss: 1.3235 - val_acc: 0.4333\n",
      "Epoch 63/150\n",
      "70/70 [==============================] - 14s 198ms/step - loss: 0.2155 - acc: 0.9857 - val_loss: 1.2965 - val_acc: 0.4333\n",
      "Epoch 64/150\n",
      "70/70 [==============================] - 14s 193ms/step - loss: 0.2112 - acc: 0.9857 - val_loss: 1.2717 - val_acc: 0.4333\n",
      "Epoch 65/150\n",
      "70/70 [==============================] - 15s 209ms/step - loss: 0.2024 - acc: 0.9714 - val_loss: 1.2749 - val_acc: 0.4333\n",
      "Epoch 66/150\n",
      "70/70 [==============================] - 14s 201ms/step - loss: 0.2040 - acc: 1.0000 - val_loss: 1.2790 - val_acc: 0.4333\n",
      "Epoch 67/150\n",
      "70/70 [==============================] - 14s 194ms/step - loss: 0.2029 - acc: 1.0000 - val_loss: 1.3119 - val_acc: 0.4333\n",
      "Epoch 68/150\n",
      "70/70 [==============================] - 15s 220ms/step - loss: 0.1902 - acc: 0.9857 - val_loss: 1.3282 - val_acc: 0.4333\n",
      "Epoch 69/150\n",
      "70/70 [==============================] - 15s 220ms/step - loss: 0.1886 - acc: 1.0000 - val_loss: 1.2962 - val_acc: 0.4333\n",
      "Epoch 70/150\n",
      "70/70 [==============================] - 15s 210ms/step - loss: 0.1941 - acc: 0.9857 - val_loss: 1.2814 - val_acc: 0.4333\n",
      "Epoch 71/150\n",
      "70/70 [==============================] - 15s 209ms/step - loss: 0.2034 - acc: 0.9714 - val_loss: 1.2417 - val_acc: 0.4333\n",
      "Epoch 72/150\n",
      "70/70 [==============================] - 15s 211ms/step - loss: 0.1873 - acc: 0.9714 - val_loss: 1.2468 - val_acc: 0.4333\n",
      "Epoch 73/150\n",
      "70/70 [==============================] - 15s 210ms/step - loss: 0.2217 - acc: 0.9714 - val_loss: 1.2815 - val_acc: 0.4333\n",
      "Epoch 74/150\n",
      "70/70 [==============================] - 15s 210ms/step - loss: 0.1830 - acc: 0.9857 - val_loss: 1.2977 - val_acc: 0.4333\n",
      "Epoch 75/150\n",
      "70/70 [==============================] - 15s 211ms/step - loss: 0.1748 - acc: 1.0000 - val_loss: 1.2975 - val_acc: 0.4333\n",
      "Epoch 76/150\n",
      "70/70 [==============================] - 15s 219ms/step - loss: 0.1870 - acc: 0.9857 - val_loss: 1.3290 - val_acc: 0.4333\n",
      "Epoch 77/150\n",
      "70/70 [==============================] - 16s 226ms/step - loss: 0.1605 - acc: 1.0000 - val_loss: 1.3270 - val_acc: 0.4333\n",
      "Epoch 78/150\n",
      "70/70 [==============================] - 16s 226ms/step - loss: 0.1734 - acc: 1.0000 - val_loss: 1.3231 - val_acc: 0.4333\n",
      "Epoch 79/150\n",
      "70/70 [==============================] - 15s 214ms/step - loss: 0.1625 - acc: 1.0000 - val_loss: 1.2950 - val_acc: 0.4333\n",
      "Epoch 80/150\n",
      "70/70 [==============================] - 15s 215ms/step - loss: 0.1662 - acc: 0.9714 - val_loss: 1.2956 - val_acc: 0.4333\n",
      "Epoch 81/150\n",
      "70/70 [==============================] - 15s 212ms/step - loss: 0.1818 - acc: 1.0000 - val_loss: 1.2874 - val_acc: 0.4333\n",
      "Epoch 82/150\n",
      "70/70 [==============================] - 15s 208ms/step - loss: 0.1589 - acc: 1.0000 - val_loss: 1.3106 - val_acc: 0.4333\n",
      "Epoch 83/150\n",
      "70/70 [==============================] - 15s 208ms/step - loss: 0.1599 - acc: 1.0000 - val_loss: 1.3043 - val_acc: 0.4333\n",
      "Epoch 84/150\n",
      "70/70 [==============================] - 15s 212ms/step - loss: 0.1746 - acc: 0.9857 - val_loss: 1.2830 - val_acc: 0.4333\n",
      "Epoch 85/150\n",
      "70/70 [==============================] - 15s 210ms/step - loss: 0.1433 - acc: 1.0000 - val_loss: 1.2375 - val_acc: 0.4333\n",
      "Epoch 86/150\n",
      "70/70 [==============================] - 15s 208ms/step - loss: 0.1461 - acc: 1.0000 - val_loss: 1.2210 - val_acc: 0.4333\n",
      "Epoch 87/150\n",
      "70/70 [==============================] - 15s 209ms/step - loss: 0.1434 - acc: 1.0000 - val_loss: 1.2249 - val_acc: 0.4333\n",
      "Epoch 88/150\n",
      "70/70 [==============================] - 15s 213ms/step - loss: 0.1680 - acc: 1.0000 - val_loss: 1.2265 - val_acc: 0.4333\n",
      "Epoch 89/150\n",
      "70/70 [==============================] - 16s 229ms/step - loss: 0.1499 - acc: 0.9857 - val_loss: 1.2271 - val_acc: 0.4333\n",
      "Epoch 90/150\n",
      "70/70 [==============================] - 16s 223ms/step - loss: 0.1569 - acc: 1.0000 - val_loss: 1.1969 - val_acc: 0.4333\n",
      "Epoch 91/150\n",
      "70/70 [==============================] - 15s 210ms/step - loss: 0.1566 - acc: 0.9714 - val_loss: 1.2088 - val_acc: 0.4333\n",
      "Epoch 92/150\n",
      "70/70 [==============================] - 15s 220ms/step - loss: 0.1599 - acc: 1.0000 - val_loss: 1.2005 - val_acc: 0.4333\n",
      "Epoch 93/150\n",
      "70/70 [==============================] - 15s 211ms/step - loss: 0.1263 - acc: 1.0000 - val_loss: 1.2364 - val_acc: 0.4333\n",
      "Epoch 94/150\n",
      "70/70 [==============================] - 15s 210ms/step - loss: 0.1327 - acc: 1.0000 - val_loss: 1.2576 - val_acc: 0.4333\n",
      "Epoch 95/150\n",
      "70/70 [==============================] - 15s 210ms/step - loss: 0.1691 - acc: 0.9714 - val_loss: 1.2390 - val_acc: 0.4333\n",
      "Epoch 96/150\n",
      "70/70 [==============================] - 15s 211ms/step - loss: 0.1811 - acc: 0.9571 - val_loss: 1.2282 - val_acc: 0.4333\n",
      "Epoch 97/150\n",
      "70/70 [==============================] - 15s 211ms/step - loss: 0.1902 - acc: 0.9714 - val_loss: 1.2606 - val_acc: 0.4333\n",
      "Epoch 98/150\n",
      "70/70 [==============================] - 16s 227ms/step - loss: 0.1410 - acc: 1.0000 - val_loss: 1.2104 - val_acc: 0.4333\n",
      "Epoch 99/150\n",
      "70/70 [==============================] - 17s 246ms/step - loss: 0.1317 - acc: 1.0000 - val_loss: 1.1782 - val_acc: 0.4333\n",
      "Epoch 100/150\n",
      "70/70 [==============================] - 15s 209ms/step - loss: 0.1760 - acc: 0.9714 - val_loss: 1.1666 - val_acc: 0.4333\n",
      "Epoch 101/150\n",
      "70/70 [==============================] - 15s 211ms/step - loss: 0.1421 - acc: 1.0000 - val_loss: 1.1661 - val_acc: 0.4333\n",
      "Epoch 102/150\n",
      "70/70 [==============================] - 15s 210ms/step - loss: 0.1383 - acc: 1.0000 - val_loss: 1.1934 - val_acc: 0.4333\n",
      "Epoch 103/150\n",
      "70/70 [==============================] - 15s 208ms/step - loss: 0.1147 - acc: 1.0000 - val_loss: 1.2142 - val_acc: 0.4333\n",
      "Epoch 104/150\n",
      "70/70 [==============================] - 18s 252ms/step - loss: 0.1448 - acc: 1.0000 - val_loss: 1.2303 - val_acc: 0.4333\n",
      "Epoch 105/150\n",
      "70/70 [==============================] - 17s 248ms/step - loss: 0.1272 - acc: 1.0000 - val_loss: 1.2083 - val_acc: 0.4333\n",
      "Epoch 106/150\n",
      "70/70 [==============================] - 15s 214ms/step - loss: 0.1334 - acc: 0.9857 - val_loss: 1.1921 - val_acc: 0.4333\n",
      "Epoch 107/150\n",
      "70/70 [==============================] - 15s 211ms/step - loss: 0.1332 - acc: 1.0000 - val_loss: 1.1987 - val_acc: 0.4333\n",
      "Epoch 108/150\n",
      "70/70 [==============================] - 15s 210ms/step - loss: 0.1260 - acc: 0.9857 - val_loss: 1.1858 - val_acc: 0.4333\n",
      "Epoch 109/150\n",
      "70/70 [==============================] - 15s 209ms/step - loss: 0.1267 - acc: 1.0000 - val_loss: 1.1702 - val_acc: 0.4333\n",
      "Epoch 110/150\n",
      "70/70 [==============================] - 15s 210ms/step - loss: 0.1135 - acc: 1.0000 - val_loss: 1.1706 - val_acc: 0.4333\n",
      "Epoch 111/150\n",
      "70/70 [==============================] - 16s 235ms/step - loss: 0.1141 - acc: 1.0000 - val_loss: 1.1781 - val_acc: 0.4333\n",
      "Epoch 112/150\n",
      "70/70 [==============================] - 16s 230ms/step - loss: 0.1270 - acc: 1.0000 - val_loss: 1.1839 - val_acc: 0.4333\n",
      "Epoch 113/150\n",
      "70/70 [==============================] - 15s 215ms/step - loss: 0.1213 - acc: 1.0000 - val_loss: 1.1815 - val_acc: 0.4333\n",
      "Epoch 114/150\n",
      "70/70 [==============================] - 16s 230ms/step - loss: 0.1093 - acc: 1.0000 - val_loss: 1.2136 - val_acc: 0.4333\n",
      "Epoch 115/150\n",
      "70/70 [==============================] - 16s 222ms/step - loss: 0.1159 - acc: 1.0000 - val_loss: 1.2234 - val_acc: 0.4333\n",
      "Epoch 116/150\n",
      "70/70 [==============================] - 17s 240ms/step - loss: 0.1209 - acc: 1.0000 - val_loss: 1.2308 - val_acc: 0.4333\n",
      "Epoch 117/150\n",
      "70/70 [==============================] - 15s 214ms/step - loss: 0.1072 - acc: 1.0000 - val_loss: 1.2062 - val_acc: 0.4333\n",
      "Epoch 118/150\n",
      "70/70 [==============================] - 15s 214ms/step - loss: 0.1282 - acc: 1.0000 - val_loss: 1.1755 - val_acc: 0.4333\n",
      "Epoch 119/150\n",
      "70/70 [==============================] - 16s 233ms/step - loss: 0.1163 - acc: 1.0000 - val_loss: 1.1885 - val_acc: 0.4333\n",
      "Epoch 120/150\n",
      "70/70 [==============================] - 16s 223ms/step - loss: 0.1088 - acc: 1.0000 - val_loss: 1.1940 - val_acc: 0.4333\n",
      "Epoch 121/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 16s 228ms/step - loss: 0.1132 - acc: 1.0000 - val_loss: 1.1604 - val_acc: 0.4333\n",
      "Epoch 122/150\n",
      "70/70 [==============================] - 16s 224ms/step - loss: 0.1288 - acc: 0.9857 - val_loss: 1.1461 - val_acc: 0.4333\n",
      "Epoch 123/150\n",
      "70/70 [==============================] - 15s 214ms/step - loss: 0.1265 - acc: 1.0000 - val_loss: 1.1024 - val_acc: 0.4333\n",
      "Epoch 124/150\n",
      "70/70 [==============================] - 15s 217ms/step - loss: 0.1129 - acc: 1.0000 - val_loss: 1.0751 - val_acc: 0.4333\n",
      "Epoch 125/150\n",
      "70/70 [==============================] - 15s 212ms/step - loss: 0.0973 - acc: 1.0000 - val_loss: 1.0805 - val_acc: 0.4333\n",
      "Epoch 126/150\n",
      "70/70 [==============================] - 15s 213ms/step - loss: 0.1086 - acc: 1.0000 - val_loss: 1.0879 - val_acc: 0.4333\n",
      "Epoch 127/150\n",
      "70/70 [==============================] - 14s 205ms/step - loss: 0.0991 - acc: 1.0000 - val_loss: 1.0942 - val_acc: 0.4333\n",
      "Epoch 128/150\n",
      "70/70 [==============================] - 15s 208ms/step - loss: 0.1190 - acc: 1.0000 - val_loss: 1.0691 - val_acc: 0.4333\n",
      "Epoch 129/150\n",
      "70/70 [==============================] - 16s 222ms/step - loss: 0.0923 - acc: 1.0000 - val_loss: 1.0696 - val_acc: 0.4333\n",
      "Epoch 130/150\n",
      "70/70 [==============================] - 15s 221ms/step - loss: 0.1218 - acc: 0.9857 - val_loss: 1.0767 - val_acc: 0.4333\n",
      "Epoch 131/150\n",
      "70/70 [==============================] - 16s 224ms/step - loss: 0.1065 - acc: 1.0000 - val_loss: 1.1298 - val_acc: 0.4333\n",
      "Epoch 132/150\n",
      "70/70 [==============================] - 16s 224ms/step - loss: 0.1157 - acc: 1.0000 - val_loss: 1.1703 - val_acc: 0.4333\n",
      "Epoch 133/150\n",
      "70/70 [==============================] - 16s 222ms/step - loss: 0.0961 - acc: 1.0000 - val_loss: 1.1372 - val_acc: 0.4333\n",
      "Epoch 134/150\n",
      "70/70 [==============================] - 16s 222ms/step - loss: 0.0921 - acc: 1.0000 - val_loss: 1.0871 - val_acc: 0.4333\n",
      "Epoch 135/150\n",
      "70/70 [==============================] - 16s 222ms/step - loss: 0.0897 - acc: 1.0000 - val_loss: 1.0653 - val_acc: 0.4333\n",
      "Epoch 136/150\n",
      "70/70 [==============================] - 15s 212ms/step - loss: 0.1017 - acc: 1.0000 - val_loss: 1.0495 - val_acc: 0.4333\n",
      "Epoch 137/150\n",
      "70/70 [==============================] - 17s 244ms/step - loss: 0.1154 - acc: 0.9857 - val_loss: 1.0477 - val_acc: 0.4333\n",
      "Epoch 138/150\n",
      "70/70 [==============================] - 17s 247ms/step - loss: 0.0904 - acc: 1.0000 - val_loss: 1.0960 - val_acc: 0.4333\n",
      "Epoch 139/150\n",
      "70/70 [==============================] - 16s 226ms/step - loss: 0.1014 - acc: 1.0000 - val_loss: 1.1383 - val_acc: 0.4333\n",
      "Epoch 140/150\n",
      "70/70 [==============================] - 17s 236ms/step - loss: 0.0875 - acc: 1.0000 - val_loss: 1.1551 - val_acc: 0.4333\n",
      "Epoch 141/150\n",
      "70/70 [==============================] - 16s 226ms/step - loss: 0.0880 - acc: 1.0000 - val_loss: 1.1601 - val_acc: 0.4333\n",
      "Epoch 142/150\n",
      "70/70 [==============================] - 15s 217ms/step - loss: 0.1119 - acc: 0.9714 - val_loss: 1.1540 - val_acc: 0.4333\n",
      "Epoch 143/150\n",
      "70/70 [==============================] - 15s 219ms/step - loss: 0.1012 - acc: 1.0000 - val_loss: 1.1937 - val_acc: 0.4333\n",
      "Epoch 144/150\n",
      "70/70 [==============================] - 16s 225ms/step - loss: 0.1077 - acc: 1.0000 - val_loss: 1.1922 - val_acc: 0.4333\n",
      "Epoch 145/150\n",
      "70/70 [==============================] - 15s 219ms/step - loss: 0.1334 - acc: 0.9857 - val_loss: 1.1972 - val_acc: 0.4333\n",
      "Epoch 146/150\n",
      "70/70 [==============================] - 15s 213ms/step - loss: 0.1059 - acc: 0.9857 - val_loss: 1.1705 - val_acc: 0.4333\n",
      "Epoch 147/150\n",
      "70/70 [==============================] - 16s 224ms/step - loss: 0.1053 - acc: 1.0000 - val_loss: 1.1761 - val_acc: 0.4333\n",
      "Epoch 148/150\n",
      "70/70 [==============================] - 15s 210ms/step - loss: 0.1399 - acc: 1.0000 - val_loss: 1.1958 - val_acc: 0.4333\n",
      "Epoch 149/150\n",
      "70/70 [==============================] - 15s 211ms/step - loss: 0.0732 - acc: 1.0000 - val_loss: 1.2310 - val_acc: 0.4333\n",
      "Epoch 150/150\n",
      "70/70 [==============================] - 15s 211ms/step - loss: 0.0801 - acc: 1.0000 - val_loss: 1.2189 - val_acc: 0.4333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xd42b32828>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO: run custom_resnet_model.fit with training data X_train, Y_train and epochs= 150, batchsize = 16, validation split of 0.3\n",
    "#Place your code here (1 line)\n",
    "custom_resnet_model.fit(X_train, Y_train, batch_size=16, epochs=150, validation_split=0.3)\n",
    "#TODO End"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model using test Images\n",
    "    Test images are stored in ~/Task2/Test Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Test Images\n",
    "#TODO: Read images of class type 'Guardrail_Barriers'\n",
    "#Note: Guardrail_Barriers has class label 0\n",
    "Path_of_the_image_folder = \"Test/Guardrail_Barriers\"\n",
    "#TODO Ends\n",
    "fileNames = []\n",
    "X_test_Guardrail_Barriers = []\n",
    "for file in os.listdir(Path_of_the_image_folder):\n",
    "    img = image.load_img(Path_of_the_image_folder+'/'+file, target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    X_test_Guardrail_Barriers.append(x)\n",
    "    fileNames.append(file)\n",
    "\n",
    "X_test_Guardrail_Barriers= np.asarray(X_test_Guardrail_Barriers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.621594261936046,-85.59612399892141.jpg is predicted as class Guardrail_Barriers\n",
      "33.758294134753676,-86.27722046076018.jpg is predicted as class Guardrail_Barriers\n",
      "33.909817698396665,-87.55789206955586.jpg is predicted as class Guardrail_Barriers\n",
      "33.468962859269766,-86.75834091424471.jpg is predicted as class Guardrail_Barriers\n",
      "30.80126420770294,-88.09467966452064.jpg is predicted as class Guardrail_Barriers\n",
      "33.463318136361124,-86.75699082594556.jpg is predicted as class Guardrail_Barriers\n",
      "33.809142237627576,-87.28961151060011.jpg is predicted as class Guardrail_Barriers\n",
      "33.909231471559416,-87.55708193714058.jpg is predicted as class Guardrail_Barriers\n",
      "33.422044650362956,-86.96000110137686.jpg is predicted as class Guardrail_Barriers\n",
      "33.855094946492294,-85.8980829219054.jpg is predicted as class Guardrail_Barriers\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,10):\n",
    "    predicted_Guardrail_Barriers = custom_resnet_model.predict(X_test_Guardrail_Barriers[i])\n",
    "    print(fileNames[i], \"is predicted as class\",classLabels[predicted_Guardrail_Barriers.argmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing images in ~Task2/Test/RumbleStrips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Test Images\n",
    "#TODO: Read images of class type 'RumbleStrips'\n",
    "#Note: RumbleStrips has class label 1\n",
    "Path_of_the_image_folder = \"Test/RumbleStrips\"\n",
    "#TODO Ends\n",
    "fileNames = []\n",
    "X_test_RumbleStrips = []\n",
    "for file in os.listdir(Path_of_the_image_folder):\n",
    "    img = image.load_img(Path_of_the_image_folder+'/'+file, target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    X_test_RumbleStrips.append(x)\n",
    "    fileNames.append(file)\n",
    "\n",
    "X_test_RumbleStrips= np.asarray(X_test_RumbleStrips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.57821430568746,-87.45259065469588.jpg is predicted as class Guardrail_Barriers\n",
      "30.80660585856723,-88.33794575108365.jpg is predicted as class Guardrail_Barriers\n",
      "30.472560521997114,-88.31997657270583.jpg is predicted as class Guardrail_Barriers\n",
      "30.94876377170364,-87.85736719485732.jpg is predicted as class Guardrail_Barriers\n",
      "30.65597568557186,-87.80248604916216.jpg is predicted as class Guardrail_Barriers\n",
      "30.237786209417237,-87.76132755812138.jpg is predicted as class Guardrail_Barriers\n",
      "30.63442937324727,-87.64025570711901.jpg is predicted as class Guardrail_Barriers\n",
      "30.94928213289987,-87.85543553710548.jpg is predicted as class Guardrail_Barriers\n",
      "30.52398299106967,-87.49696627190343.jpg is predicted as class Guardrail_Barriers\n",
      "30.53876209810701,-87.55018054535974.jpg is predicted as class RumbleStrips\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,10):\n",
    "    predicted_RumbleStrips = custom_resnet_model.predict(X_test_RumbleStrips[i])\n",
    "    print(fileNames[i], \"is predicted as class\",classLabels[predicted_RumbleStrips.argmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The rumblestrips test case only had one correct classification, guardrails were completely correct "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
